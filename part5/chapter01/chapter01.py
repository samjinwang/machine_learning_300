# -*- coding: utf-8 -*-
"""[ì‹¤ìŠµ]Chapter 01_Rating Matrixë¥¼ í™œìš©í•œ ì˜í™” ì¶”ì²œ ëª¨ë¸.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1n5_eG3GK3ZkUcethRWn97DqMpLBca8lV

# ì£¼ì œ : ì¶”ì²œ ì‹œìŠ¤í…œ - ì˜í™” ë°ì´í„°ì…‹ê³¼ Rating Matrixë¥¼ í™œìš©í•˜ì—¬ ì¶”ì²œ ëª¨ë¸ í•™ìŠµí•˜ê¸°
----------

## ì‹¤ìŠµ ê°€ì´ë“œ
    1. ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ì—¬ Colabì— ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
    2. í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” ëª¨ë‘ ì½”ë“œë¡œ ì‘ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
    3. ì½”ë“œëŠ” ìœ„ì—ì„œë¶€í„° ì•„ë˜ë¡œ ìˆœì„œëŒ€ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.
    4. ì „ì²´ ë¬¸ì œ êµ¬ì„±ì€ ì¢Œì¸¡ ì²« ë²ˆì§¸ ì•„ì´ì½˜ì„ í†µí•´ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    
    
## ë°ì´í„° ì†Œê°œ
    - ì´ë²ˆ ì£¼ì œëŠ” MovieLens Datasetì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
    - íŒŒì¼ì€ ë‘ ê°œ ì´ë©°, ê°ê°ì˜ ì»¬ëŸ¼ì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.
    
    1. ratings.dat
    user_id : ì˜í™”ë¥¼ ì‹œì²­í•œ ì‚¬ìš©ì ì•„ì´ë””
    movie_id : ì˜í™”ì˜ ì•„ì´ë””
    rating : ì‚¬ìš©ìê°€ ì˜í™”ë¥¼ í‰ê°€í•œ ì ìˆ˜
    time : ì‚¬ìš©ìê°€ ì˜í™”ë¥¼ ì‹œì²­í•œ ì‹œê°„
    
    2. movies.dat
    movie_id : ì˜í™”ì˜ ì•„ì´ë””
    title : ì˜í™” ì œëª©
    genre : ì˜í™” ì¥ë¥´

    
- ë°ì´í„° ì¶œì²˜: https://grouplens.org/datasets/movielens/


## ìµœì¢… ëª©í‘œ
    - CF(Collaborative Filtering) ê¸°ë°˜ ì¶”ì²œ ëª¨ë¸ì˜ ì´í•´
    - Matrix Factorization ê¸°ë°˜ ì¶”ì²œ ëª¨ë¸ì˜ ì´í•´
    - KNN, SVD ì•Œê³ ë¦¬ì¦˜ì— ëŒ€í•œ ì´í•´
    - í›ˆë ¨ëœ ëª¨ë¸ì˜ ê²°ê³¼ë¥¼ í•´ì„í•˜ëŠ” ë°©ë²• ìŠµë“
    - ëª¨ë¸ì˜ ì¶”ì²œ ê²°ê³¼ë¥¼ í‰ê°€í•˜ëŠ” ë°©ë²• ìŠµë“

- ì¶œì œì : ìœ¤ê¸°íƒœ ê°•ì‚¬
---

## Step 1. ë°ì´í„° ì „ì²˜ë¦¬ ê³¼ì •

### ë¬¸ì œ 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
"""

import pandas as pd

rating_url = 'https://raw.githubusercontent.com/yoonkt200/python-data-analysis/master/data/ml-1m/ratings.dat'
rating_df = pd.io.parsers.read_csv(rating_url, names=['user_id', 'movie_id', 'rating', 'time'], delimiter='::', engine ='python')
rating_df.head()

movie_url = 'https://raw.githubusercontent.com/yoonkt200/python-data-analysis/master/data/ml-1m/movies.dat'
movie_df = pd.io.parsers.read_csv(movie_url, names=['movie_id', 'title', 'genre'], delimiter='::', engine ='python', encoding='ISO-8859-1')
movie_df.head()

"""### ë¬¸ì œ 2. EDA - ì‚¬ìš©ì ìˆ˜ì™€ ì˜í™”ì˜ ìˆ˜ íƒìƒ‰"""

# unique() í•¨ìˆ˜ë¡œ ì‚¬ìš©ì ìˆ˜ì™€ ì˜í™” ìˆ˜ íƒìƒ‰
len(rating_df['user_id'].unique())

len(movie_df['movie_id'].unique())

"""### ë¬¸ì œ 3. EDA - ì˜í™” í‰ê°€ ì ìˆ˜ì˜ ë¶„í¬ íƒìƒ‰"""

# hist() í•¨ìˆ˜ë¡œ íˆìŠ¤í† ê·¸ë¨ ê·¸ë˜í”„ ìƒì„±'
import matplotlib.pyplot as plt
rating_df['rating'].hist()



"""## Step 2. CF-based ëª¨ë¸ë§ (KNN)

### Rating Matrixì™€ Colaborative Filtering (CF)
----------

#### Rating Matrix

![rating matrix](https://www.researchgate.net/profile/Giuseppe_Manco3/publication/220907096/figure/fig1/AS:305570830667776@1449865171054/An-example-of-rating-matrix.png)

    1. Userë¥¼ Row, Itemì„ Columnìœ¼ë¡œ í•˜ë©° Valueë¥¼ Ratingìœ¼ë¡œ í•˜ëŠ” í–‰ë ¬
    2. Ratingì˜ ì¢…ë¥˜
      - Explicit Feedback : ì˜í™” ì ìˆ˜, ë¦¬ë·° ì ìˆ˜, ì¢‹ì•„ìš” í‘œì‹œ...
      - Implicit Feedback : ì¡°íšŒ, ì‹œì²­, êµ¬ë§¤, ì°œ í‘œì‹œ...
    3. Rating Matrixë¥¼ ì¶”ì²œ ëª¨ë¸ë¡œ í™œìš©í•˜ëŠ” ë°©ë²•
      - Colaborative Filtering (CF)
      - Matrix Factorization (MF)

-----

#### Colaborative Filtering (CF)

![CF](https://t1.daumcdn.net/cfile/tistory/9970CE495AF71C0C06)

> ê³ ê°ë“¤ì˜ ì„ í˜¸ë„ì™€ ê´€ì‹¬ í‘œí˜„ì„ ë°”íƒ•ìœ¼ë¡œ ì„ í˜¸ë„, ê´€ì‹¬ì—ì„œ ë¹„ìŠ·í•œ íŒ¨í„´ì„ ê°€ì§„ ê³ ê°ë“¤ì„ ì‹ë³„í•´ ë‚´ëŠ” ê¸°ë²•ì´ë‹¤. ë¹„ìŠ·í•œ ì·¨í–¥ì„ ê°€ì§„ ê³ ê°ë“¤ì—ê²Œ ì„œë¡œ ì•„ì§ êµ¬ë§¤í•˜ì§€ ì•Šì€ ìƒí’ˆë“¤ì€ êµì°¨ ì¶”ì²œí•˜ê±°ë‚˜ ë¶„ë¥˜ëœ ê³ ê°ì˜ ì·¨í–¥ì´ë‚˜ ìƒí™œ í˜•íƒœì— ë”°ë¼ ê´€ë ¨ ìƒí’ˆì„ ì¶”ì²œí•˜ëŠ” í˜•íƒœì˜ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•˜ê¸° ìœ„í•´ ì‚¬ìš©ëœë‹¤.
    
    1. User-based
    2. Item-based

-----

### ë¬¸ì œ 4. ëª¨ë¸ë§ - Train/Test ë°ì´í„° ë¶„ë¦¬
"""

!pip install surprise

from surprise import Dataset, Reader
from surprise.model_selection import train_test_split

# Reader, Dataset ì˜¤ë¸Œì íŠ¸ë¡œ í•™ìŠµìš© ë°ì´í„°ì…‹ ìƒì„± ë° ë¶„ë¦¬
reader = Reader(rating_scale = (1,5)) #í‰ê°€ ì ìˆ˜ ë²”ìœ„
data = Dataset.load_from_df(rating_df[['user_id', 'movie_id', 'rating']], reader) #ë¶ˆëŸ¬ì˜¨ í‰ê°€ë°ì´í„°ë¥¼ ì½ìŒ
trainset, testset = train_test_split(data, test_size = 0.25) #í•™ìŠµ,í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ë¶„ë¦¬

"""### ë¬¸ì œ 5. ëª¨ë¸ë§ - KNN ëª¨ë¸ í•™ìŠµ

-----

#### KNN (K-Nearest Neighbor) ì•Œê³ ë¦¬ì¦˜

![knn](http://i.imgur.com/gLBo1gX.png)

    [KNNì˜ ëŒ€ëµì ì¸ ì´í•´]
    1. ìƒˆë¡œìš´(í˜¹ì€ íŠ¹ì •í•œ) ë°ì´í„° í¬ì¸íŠ¸ Xê°€ ìˆì„ ë•Œ, Xì™€ ê°€ì¥ ìœ ì‚¬í•œ kê°œë¥¼ ì´ìš©í•˜ì—¬ ë°ì´í„° í¬ì¸íŠ¸ Xì˜ ìœ„ì¹˜ë¥¼ ì°¾ëŠ” ì•Œê³ ë¦¬ì¦˜
    2. euclidean distance, cosine similarity ë“±ì„ ê¸°ì¤€ìœ¼ë¡œ ìœ ì‚¬í•œ kê°œë¥¼ ê³„ì‚°
    3. ë¶„ë¥˜(classification) ë¬¸ì œì˜ ê²½ìš°ëŠ” kê°œì˜ í¬ì¸íŠ¸ì—ì„œ ê°€ì¥ ë§ì´ ë“±ì¥í•œ classë¡œ í• ë‹¹
    4. ì˜ˆì¸¡(regression) ë¬¸ì œì˜ ê²½ìš°ëŠ” kê°œ í¬ì¸íŠ¸ì˜ í‰ê·  ê°’, í˜¹ì€ ê°€ì¤‘ì¹˜ ê°’ ë“±ìœ¼ë¡œ Xì˜ ê°’ì„ ì˜ˆì¸¡

#### Surpriseì˜ KNN

> A basic collaborative filtering algorithm. The prediction ğ‘ŸÌ‚ ğ‘¢ğ‘– is set as

![suprise knn](https://raw.githubusercontent.com/yoonkt200/FastCampusDataset/master/images/knn.png)

###### (https://surprise.readthedocs.io/en/stable/knn_inspired.html)
    
    [ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ëŒ€ëµì ì¸ í•™ìŠµ ê³¼ì •]
    1. User-based CF
    2. ìœ ì € Aì™€ ê°€ì¥ ì˜í™”ë¥¼ ìœ ì‚¬í•˜ê²Œ í‰ê°€í•œ ìœ ì € këª…ì„ ì„ ì •
    3. këª…ì˜ ìœ ì €ê°€ ì˜í™” aë¥¼ í‰ê°€í•œ ì ìˆ˜ë¥¼ í™œìš©í•˜ì—¬ ìœ„ì˜ ì‹ëŒ€ë¡œ ì ìˆ˜ë¥¼ ê³„ì‚°í•¨
    4. ì´ì™€ ê°™ì€ ë°©ì‹ìœ¼ë¡œ Rating Matrixë¥¼ ì™„ì„±
-----
    [Similarity]
    1. ê°€ì¥ ì¼ë°˜ì ì¸ Similarity ê³„ì‚° ë°©ì‹ì€ cosine similarity
    2. ë‹¤ë¥¸ ë°©ì‹ì€ euclidean distance, jaccard index, pearson correlation ë“±ì´ ìˆìŒ

![cosine](https://raw.githubusercontent.com/yoonkt200/FastCampusDataset/master/images/cosine.png)
-----
"""

# KNN ì´í•´ë¥¼ ë•ê¸° ìœ„í•œ ì°¸ê³  ì½”ë“œ
ab = (0.9 * 4) + (0.8 * 3) + (0.7 * 5) + (0.6 * 1)
bb = (0.9) + 0.8 + 0.7 + 0.6

ab/bb

from surprise import KNNBasic #ëª¨ë¸ ì™„ì„±ì‹œì¼œì£¼ëŠ” í´ë˜ìŠ¤

# KNNBasic ëª¨ë¸ í•™ìŠµ
algo = KNNBasic(k = 40, min_k = 1, sim_options={'user_based': True, 'name':'cosine'}) #sim_options. itembase ë˜ëŠ” user base, ì–´ë–¤ ë°©ì‹ìœ¼ë¡œ ìœ ì‚¬ë„ ì°¾ì„ì§€
algo.fit(trainset)
predictions = algo.test(testset)
predictions

"""### ë¬¸ì œ 6. ëª¨ë¸ë§ - RMSE í‰ê°€"""

from surprise import accuracy #ëª¨ë¸ í‰ê°€ í•¨ìˆ˜
accuracy.rmse(predictions)
# accuracyë¡œ rmse í‰ê°€

"""### ë¬¸ì œ 7. ëª¨ë¸ í‰ê°€ - í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì—ì„œ ì¼ë¶€ ê²°ê³¼ í™•ì¸"""

# test í•¨ìˆ˜ì˜ ê²°ê³¼ë¥¼ í™œìš©í•˜ì—¬ ëª¨ë¸ì„ ì •ì„±ì ìœ¼ë¡œ í‰ê°€
predictions = algo.test(testset[:20])

predictions

"""## Step 3. MF-based ëª¨ë¸ë§ (SVD)

### ë¬¸ì œ 8. ëª¨ë¸ë§ - Train/Test ë°ì´í„° ë¶„ë¦¬
"""

# Reader, Dataset ì˜¤ë¸Œì íŠ¸ë¡œ í•™ìŠµìš© ë°ì´í„°ì…‹ ìƒì„± ë° ë¶„ë¦¬
from surprise import Dataset, Reader
from surprise.model_selection import train_test_split

# Reader, Dataset ì˜¤ë¸Œì íŠ¸ë¡œ í•™ìŠµìš© ë°ì´í„°ì…‹ ìƒì„± ë° ë¶„ë¦¬
reader = Reader(rating_scale = (1,5)) #í‰ê°€ ì ìˆ˜ ë²”ìœ„
data = Dataset.load_from_df(rating_df[['user_id', 'movie_id', 'rating']], reader) #ë¶ˆëŸ¬ì˜¨ í‰ê°€ë°ì´í„°ë¥¼ ì½ìŒ
trainset, testset = train_test_split(data, test_size = 0.25) #í•™ìŠµ,í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ë¶„ë¦¬

"""### ë¬¸ì œ 9. ëª¨ë¸ë§ - SVD ëª¨ë¸ í•™ìŠµ

-----

#### Matrix Factorizationì˜ ê°œë…

![MF](https://t1.daumcdn.net/cfile/tistory/99EAC1455AF71F3E31)

![MF2](https://media.springernature.com/lw785/springer-static/image/chp%3A10.1007%2F978-3-319-65930-5_47/MediaObjects/455696_1_En_47_Fig3_HTML.gif)

    [MFì˜ ëŒ€ëµì ì¸ ì´í•´]
    1. ì›ë˜ì˜ í–‰ë ¬ì„ ë‹¤ë¥¸ 2ê°œ í–‰ë ¬ë¡œ ë¶„í•´í•˜ê³ , ì´ë¥¼ ë‹¤ì‹œ ì›ë˜ ëª¨ì–‘ìœ¼ë¡œ ë§Œë“œëŠ” ê³¼ì •ì„ Factorization ì´ë¼ê³  í•¨.
    2. ê·¸ ê³¼ì •ì—ì„œ Latent Factor ë¼ëŠ” ê²ƒì„ í™œìš©í•˜ì—¬, í–‰ê³¼ ì—´ì˜ ì„±ì§ˆì„ ë§Œë“¤ì–´ë‚¼ ìˆ˜ ìˆìŒ.
    3. latent factorë¥¼ ì¶©ë¶„íˆ ë§ì´ ë§Œë“¤ê²Œ ë˜ë©´, ìœ ì €ì™€ ì•„ì´í…œì˜ ì„±ì§ˆì„ ë²¡í„°ë¡œ í‘œí˜„ ê°€ëŠ¥.
    4. ì¼ë°˜ì ìœ¼ë¡œ ì§€ë„ í•™ìŠµì„ í†µí•´ Pì™€ Që¥¼ ì°¾ê²Œ ë˜ê³ , ì´ë¥¼ Model-based CF ë¼ê³  í•˜ê¸°ë„ í•¨.

#### Surpriseì˜ SVD

> The famous SVD algorithm, as popularized by Simon Funk during the Netflix Prize. When baselines are not used, this is equivalent to Probabilistic Matrix Factorization

> The prediction ğ‘ŸÌ‚ ğ‘¢ğ‘– is set as:

![r_ui](https://raw.githubusercontent.com/yoonkt200/FastCampusDataset/master/images/r_ui_1.png)

###### (https://surprise.readthedocs.io/en/stable/matrix_factorization.html)
    
    [ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ëŒ€ëµì ì¸ í•™ìŠµ ê³¼ì •]
    1. Model-based MF
    2. ì´ë¯¸ ì ìˆ˜ê°€ ì¡´ì¬í•˜ëŠ” r_uië¥¼ ê¸°ì¤€ìœ¼ë¡œ P, Që¥¼ í•™ìŠµ.
    3. íŠ¹ì • epoch, í˜¹ì€ ìˆ˜ë ´ ì¡°ê±´ì— ë‹¬í•  ë•Œ ê¹Œì§€ í•™ìŠµ (Gradient Descent)

![r_ui](https://raw.githubusercontent.com/yoonkt200/FastCampusDataset/master/images/r_ui_2.png)

![r_ui](https://raw.githubusercontent.com/yoonkt200/FastCampusDataset/master/images/r_ui_3.png)

-----
"""

from surprise import SVD

# SVD ëª¨ë¸ í•™ìŠµ
algo = SVD()
algo.fit(trainset)
predictions = algo.test(testset)

"""### ë¬¸ì œ 10. ëª¨ë¸ë§ - RMSE í‰ê°€"""

# ì•ì—ì„œì™€ ë™ì¼í•˜ê²Œ accuracy í•¨ìˆ˜ë¡œ rmse í‰ê°€
accuracy.rmse(predictions)

"""### ë¬¸ì œ 11. ëª¨ë¸ë§ & ì‹œê°í™” - RMSEë¥¼ ê°œì„ í•˜ëŠ” íŒŒë¼ë¯¸í„° íŠœë‹ ìë™í™”"""

import time

param_list = [10, 50, 100, 150, 200]
rmse_list_by_factors = []
ttime_list_by_factors = []
for n in param_list:    
    train_start = time.time()
    algo = SVD(n_factors=n)
    algo.fit(trainset)
    train_end = time.time()
    print("training time of model: %.2f seconds" % (train_end - train_start))
    print("RMSE of test dataset in SVD model, n_factors=" + str(n))
    predictions = algo.test(testset)
    rmse_result = accuracy.rmse(predictions)
    rmse_list_by_factors.append(rmse_result)
    ttime_list_by_factors.append((train_end - train_start))
    print("------------------------------------")
print("searching n_factors is finish.")

# pltì˜ plot í•¨ìˆ˜ë¡œ ê²°ê³¼ ì‹œê°í™”
plt.plot(param_list, rmse_list_by_factors)
plt.title('RMSE by n_factors of SVD')
plt.ylabel('RMSE', fontsize=12)
plt.xlabel('n_factors', fontsize=12)
plt.show()

"""### ë¬¸ì œ 12. ëª¨ë¸ í‰ê°€ - ìµœì¢… RMSE í‰ê°€"""

# accuracyë¡œ rmse í‰ê°€
algo = SVD(n_factors=50)
algo.fit(trainset)
predictions = algo.test(testset)
accuracy.rmse(predictions)

"""### ë¬¸ì œ 13. ëª¨ë¸ í‰ê°€ - í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì—ì„œ ì¼ë¶€ ê²°ê³¼ í™•ì¸"""

predictions = algo.test(testset[:20])

for _, iid, r_ui, predicted_rating, _ in predictions:
    print("Item id", iid, "|", "real rating :", r_ui, "|", "predicted rating :", predicted_rating)

"""## Step 4. ì¶”ì²œ ê²°ê³¼ í‰ê°€

-----

#### CF, MF ê¸°ë°˜ ì¶”ì²œì‹œìŠ¤í…œì˜ ê°€ì •(í•œê³„)

    [ê°€ì • : ì‚¬ìš©ìì˜ ê³¼ê±° PreferenceëŠ” ë¯¸ë˜ì—ì„œë„ ë™ì¼í•˜ë‹¤]
    1. Time Seriesë¡œ ì¶”ì •ëœ ì„ í˜¸ë„ê°€ ì•„ë‹Œ, Estimate ë˜ê±°ë‚˜ Factorized ëœ ì ìˆ˜
    2. Aì‹œì ì— í‰ê°€í•œ ì„ í˜¸ë„ì™€, Bì‹œì ì— í‰ê°€í•œ ì„ í˜¸ë„ê°€ ë™ì¼ ì„ ì—ì„œ í•™ìŠµë¨
    3. Test ë°ì´í„°ì— ëŒ€í•œ í‰ê°€ ì—­ì‹œ, ì‹œê°„ì´ ê³ ë ¤ë˜ì§€ ì•Šì€ "ëœë¤í•œ ë¹ˆê³µê°„ ì°¾ê¸°" ì‹ìœ¼ë¡œ í‰ê°€ë¨

- ì´ë²ˆ ì±•í„°ì˜ ëª©í‘œ
  - `í•™ìŠµì€ ê·¸ë ‡ë‹¤ ì¹˜ê³ , í‰ê°€ë¼ë„ ì‹œê°„ì„ ê³ ë ¤í•´ì„œ í•´ë³´ì`

### ë¬¸ì œ 14. ì¶”ì²œ ê²°ê³¼ í‰ê°€ - ì‚¬ìš©ìë³„ ì „ì²´ ì‹œì²­ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ
"""

# groupbyì™€ apply í•¨ìˆ˜ë¥¼ ì´ìš©í•˜ì—¬ ì‚¬ìš©ìë³„ ì‹œì²­ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ



"""### ë¬¸ì œ 15. ì¶”ì²œ ê²°ê³¼ í‰ê°€ - íŠ¹ì • ì‹œê°„ ê¸°ì¤€ ì‚¬ìš©ìë³„ Train/Test ì‹œì²­ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ
ì¶”ì²œ ê²°ê³¼ í‰ê°€ - íŠ¹ì • ì‹œê°„ ê¸°ì¤€ ìœ ì €ë³„ ì‹œì²­ ëª©ë¡ ì¶”ì¶œ (Train/Testê³¼ ë™ì¼ ê¸°ì¤€)
"""

# ì‹œê°„ë³„ ì‹œì²­ ë¶„í¬ íƒìƒ‰
rating_df['time'].hist(bins=100)

# 8:2 ë¡œ ë¶„í• í•  ìˆ˜ ìˆëŠ” ì‹œê°„ ì§€ì •
rating_df['time'].quantile(q=0.8, interpolation='nearest')

# ì§€ì •ëœ ì‹œê°„ìœ¼ë¡œ ë°ì´í„°ì…‹ ë¶„ë¦¬

# íŠ¹ì • ì‹œê°„ ì´í›„ë¥¼ ëŒ€ìƒìœ¼ë¡œ ë‹¤ì‹œ í•œ ë²ˆ ì‚¬ìš©ìë³„ ì‹œì²­ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ

"""### ë¬¸ì œ 16. ì¶”ì²œ ê²°ê³¼ í‰ê°€ - ëª¨ë¸ ê¸°ë°˜ ì‚¬ìš©ìë³„ ì„ í˜¸ ì‹œì²­ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ"""

# ìœ„ì—ì„œ ì¶”ì¶œí•œ í•™ìŠµ ë°ì´í„°ì…‹ìœ¼ë¡œ SVD ëª¨ë¸ ë‹¤ì‹œ í•™ìŠµ

# anti dataset ìƒì„±
test_data = train_data.build_anti_testset()

# test í•¨ìˆ˜ì˜ ê²°ê³¼ë¥¼ í™œìš©í•˜ì—¬ ëª¨ë¸ì„ ì •ì„±ì ìœ¼ë¡œ í‰ê°€
predictions = algo.test(testset[:20])

# ëª¨ë¸ì— ì˜í•´ ë‹¤ìŒì„ ìƒì„± : ì‹œì²­í•˜ì§€ ì•Šì€ ì˜í™”ì˜ ì˜ˆìƒ ì ìˆ˜
predictions = algo.test(test_data)
estimated_unwatched_dict = {}

for uid, iid, _, predicted_rating, _ in predictions:
  pass  # ì‹œì²­í•˜ì§€ ì•Šì€ ì˜í™”ì˜ ì˜ˆìƒ ì ìˆ˜ ì¶”ì¶œ

"""### ë¬¸ì œ 17. ì¶”ì²œ ê²°ê³¼ í‰ê°€ - ì˜ˆìƒ ì„ í˜¸ ë¦¬ìŠ¤íŠ¸ì™€ ì‹¤ì œ ì‹œì²­ë¦¬ìŠ¤íŠ¸ë¡œ MAP@K ê³„ì‚°

-----

![confusion_matrix](https://raw.githubusercontent.com/yoonkt200/FastCampusDataset/master/images/confusion_matrix.png)

    [Confusion Matrixì™€ Recall]
    1. ë¶„ë¥˜ ë¬¸ì œì—ì„œ ì‚¬ìš©í•˜ëŠ” ëŒ€í‘œì ì¸ í‰ê°€ ê¸°ì¤€
    2. ë¬´ì–¸ê°€ì˜ ì‹¤ì œ í´ë˜ìŠ¤(binary), ê·¸ë¦¬ê³  ì˜ˆìƒí•œ í´ë˜ìŠ¤(binary)ë¥¼ ë¹„êµí•˜ê¸° ìœ„í•œ ë§¤íŠ¸ë¦­ìŠ¤
    3. ì´ ì¤‘ Precisionì€ í”íˆ "ì •í™•ë„" ì´ë¼ê³  ë¶ˆë¦¬ëŠ” ì§€í‘œë¡œ, ë§ë‹¤ê³  ì˜ˆì¸¡í•œ ê²ƒ ì¤‘ì— ì‹¤ì œë¡œ ë§ëŠ” ê²ƒì˜ ë¹„ìœ¨ì„ ì˜ë¯¸í•¨.

-----

    [ì¶”ì²œì‹œìŠ¤í…œê³¼ Precision, Recall]
    1. ì¶”ì²œì‹œìŠ¤í…œì— ì´ë¥¼ ëŒ€ì…í•´ë³´ì
    2. ìœ ì €Aê°€ ì‹¤ì œë¡œ ì‹œì²­í•œ ì˜í™”ë“¤ì„ a, ëª¨ë¸ì´ ìœ ì € Aê°€ ë³¼ ê²ƒì´ë¼ê³  ì˜ˆì¸¡í•œ ì˜í™”ë“¤ì„ bë¼ê³  ê°€ì •
    3. ì´ ë•Œ ëª¨ë¸ì´ 10ê°œì˜ ì˜í™”ë¥¼ ì˜ˆì¸¡ í–ˆë‹¤ë©´ Top 10 Precision ê³„ì‚°í•  ìˆ˜ ìˆìŒ.
    4. Recall ì—­ì‹œ ë§ˆì°¬ê°€ì§€ì˜ ë°©ë²•ìœ¼ë¡œ êµ¬í•  ìˆ˜ ìˆìŒ.
    5. Precisionê³¼ Recallì— ëŒ€í•œ ì„ íƒ ê¸°ì¤€ì€ ìƒí™©ë§ˆë‹¤ ë‹¤ë¥´ì§€ë§Œ, ì¶”ì²œì‹œìŠ¤í…œì—ì„œ ì¼ë°˜ì ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” ì§€í‘œëŠ” "MAP"
    6. MAP(Mean Average Precision) : ì¶”ì²œì‹œìŠ¤í…œì—ì„œëŠ” ê° ìœ ì €ë§ˆë‹¤ì˜ Precisionì„ ê³„ì‚°í•œ ë’¤, ì´ê²ƒì„ ëª¨ë“  ì¶”ì²œ ëŒ€ìƒ ìœ ì €ë¡œ í™•ì¥í•˜ì—¬ í‰ê· ì ì¸ ì§€í‘œë¥¼ ê³„ì‚°í•œ ê²ƒì´ë¼ê³  ë³¼ ìˆ˜ ìˆìŒ.
"""

# 4ì  ì´ìƒì„ ì¤€ test ì‹œì²­ë¦¬ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ

user_metric = []

# ìœ ì €ë³„ kê°œì˜ ì„ í˜¸ ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ
k = 3
for user in estimated_unwatched_dict:
  pass  # ì„ í˜¸ ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ

# ìœ ì € í•œ ëª…ì˜ Precision ê³„ì‚°
predictive_values = ??
actual_values = ??
tp = [pv for pv in predictive_values if pv in actual_values]
len(tp) / len(predictive_values)

# user metricë¥¼ ì¸ìë¡œ ë°›ëŠ” ì¼ë°˜í™”ëœ Precision ê³„ì‚° í•¨ìˆ˜ ì •ì˜
def get_map(user_list):
  pass

get_map(user_metric)

"""### ë¬¸ì œ 18. ì¶”ì²œ ê²°ê³¼ í‰ê°€ & ì‹œê°í™” - K íŒŒë¼ë¯¸í„° ë³„ ì¶”ì²œ ê²°ê³¼ ì‹œê°í™”"""

# user metricë¥¼ ì¸ìë¡œ ë°›ëŠ” ì¼ë°˜í™”ëœ Precision ê³„ì‚° í•¨ìˆ˜ ì •ì˜
def get_map_topk(k):
  pass

# ë°˜ë³µë¬¸, plot í•¨ìˆ˜ë¥¼ í™œìš©í•˜ì—¬ k íŒŒë¼ë¯¸í„° íŠœë‹ ê´€ì°° ë° ìë™í™”

