# -*- coding: utf-8 -*-
"""Chapter 1 - 자동으로 모은 데이터는 분석하기 어렵다면서_ 자동으로 모은 중고 자동차 데이터를 분석해보자!(문제).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-KaDQgGqnMqXCAlyhnoXj7t8I7oJAOmM

# 주제 : 자동으로 모은 데이터는 분석하기 어렵다면서? 자동으로 모은 중고 자동차 데이터를 분석해보자!
----------

## 실습 가이드
    1. 데이터를 다운로드하여 Colab에 불러옵니다.
    2. 필요한 라이브러리는 모두 코드로 작성되어 있습니다.
    3. 코드는 위에서부터 아래로 순서대로 실행합니다.
    
    
## 데이터 소개
    - 이번 주제는 Used Cars Dataset을 사용합니다.
    - 파일은 한 개이며, 각각의 컬럼은 아래와 같습니다.
    
    - vehicles.csv
    id : 중고차 거래의 아이디
    url : 중고차 거래 페이지
    region : 해당 거래의 관리 지점
    region_url : 거래 관리 지점의 홈페이지
    price : 기입된 자동차의 거래가
    year : 거래가 기입된 년도
    manufacturer : 자동차를 생산한 회사
    model : 자동차 모델명
    condition : 자동차의 상태
    cylinders : 자동차의 기통 수
    fuel : 자동차의 연료 타입
    odometer : 자동차의 운행 마일 수
    title_status : 자동차의 타이틀 상태 (소유주 등록 상태)
    transmission : 자동차의 트랜스미션 종류
    vin : 자동차의 식별 번호 (vehicle identification number)
    drive : 자동차의 구동 타입
    size : 자동차 크기
    type : 자동차의 일반 타입 (세단, ...)
    paint_color : 자동차 색상
    image_url : 자동차 이미지
    description : 세부 설명
    county : 실수로 생성된 미사용 컬럼
    state : 거래가 업로드된 미 주
    lat : 거래가 업로드된 곳의 위도
    long : 거래가 업로드된 곳의 경도
    
    
- 데이터 출처: https://www.kaggle.com/austinreese/craigslist-carstrucks-data

## 최종 목표
    - 스크래핑된 dirty 데이터 클리닝 방법 이해
    - 다양한 종류의 데이터 정규화 방법 습득
    - 데이터 시각화를 통한 인사이트 습득 방법의 이해
    - Scikit-learn 기반의 모델 학습 방법 습득
    - XGBoost, LightGBM 기반의 모델 학습 방법 습득
    - 학습된 모델의 평가 방법 및 시각화 방법 습득

- 출제자 : 신제용 강사
---

## Step 0. 데이터 스크래핑이 대하여

### 스크래핑을 이용한 자동 데이터 습득

*   데이터의 형식을 예측 후 그대로 고정적으로 지정해서 가져옴 (데이터 구성이 예측이 벗어난 경우 (리뉴얼이나, 팝업창때메 평소랑 다름)는 동작이 잘 안될수 도 있다)
* 고로 스크래핑 데이터는 오류가 많을 수 밖에 없다 -> 데이터가 비어있거나 형식이 틀리고, 아웃라이어가 많다
(문자열 같은경우 앞뒤 공백이 많고, html 태그가 같이 포함되는경우가 많다, 인코딩에 의해 깨진 문자도 많다.)
(숫자같은 경우는 최대값이나 최소값으로 잘못기입되는 경우가 많다. 숫자대신 문자열이 들어가 분석에 차질이 생김)

### 스크래핑된 데이터에서 아웃라이어의 특징

## Step 1. 데이터셋 준비하기
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

"""### 문제 1. Colab Notebook에 Kaggle API 세팅하기

"""

import os

# os.environ을 이용하여 Kaggle API Username, Key 세팅하기
# os.environ을 이용하여 Kaggle API Username, Key 세팅하기
os.environ['KAGGLE_USERNAME'] = 'samjinwang'
os.environ['KAGGLE_KEY'] = 'e808743bea20e4a89b105256b9d5941b'

"""### 문제 2. 데이터 다운로드 및 압축 해제하기

"""

# Li# Linux 명령어로 Kaggle API를 이용하여 데이터셋 다운로드하기 (!kaggle ~)
# Linux 명령어로 압축 해제하기
!rm *.* #모든 파일 삭제 추후 다시 실행시 파일을 엎어쓰는지 선택을 안해도 됨
!kaggle datasets download -d austinreese/craigslist-carstrucks-data
!unzip '*.zip'

"""### 문제 3. Pandas 라이브러리로 csv파일 읽어들이기

"""

df = pd.read_csv('vehicles.csv')

"""## Step 2. EDA 및 데이터 기초 통계 분석

### 문제 4. 불필요한 데이터 데이터프레임에서 제거하기
"""

# DataFrame에서 제공하는 메소드를 이용하여 각 데이터프레임의 구조 분석하기 (head(), info(), describe())
# 데이터프레임에서 불필요한 컬럼 제거하기

"""### 문제 5. 범주형 데이터의 통계 분석하기

"""

# 범주형 데이터의 값의 범위, 기초 통계 분석하기

"""### 문제 6. 수치형 데이터의 통계 분석하기"""

# 수치형 데이터의 값의 범위, 기초 통계 분석하기

"""## Step 3. 데이터 클리닝 수행하기

### 문제 7. 범주형 데이터 시각화하여 분석하기
"""

# Boxplot 계열로 범주형 데이터를 시각화하여 분석하기

"""### 문제 8. 범주형 데이터 클리닝하기"""

# 범주형 데이터를 아래 방법 중 적절히 판단하여 처리하기
# 1. 결손 데이터가 포함된 Row를 제거
# 2. 결손 데이터를 others 범주로 변경하기
# 3. 지나치게 소수로 이루어진 범주를 others 범주로 변경하기

"""### 문제 9. 수치형 데이터 시각화하여 분석하기"""

# Seaborn을 이용하여 범주형 데이터를 시각화하여 분석하기
# Hint) 값의 범위가 너무 넓을 경우 histplot() 등이 잘 동작하지 않으므로, rugplot을 활용

"""### 문제 10. 수치형 데이터 클리닝하기"""

# quantile() 메소드를 이용하여 outlier 제거하고 시각화하여 확인하기

"""### 문제 11. 컬럼간의 Correlation Heatmap으로 시각화하기"""



"""## Step 4. 모델 학습을 위한 데이터 전처리

### 문제 12. StandardScaler를 이용해 수치형 데이터 표준화하기
"""

from sklearn.preprocessing import StandardScaler

# StandardScaler를 이용해 수치형 데이터를 표준화하기
X_num =

# get_dummies를 이용해 범주형 데이터를 one-hot 벡터로 변경하기
X_cat =

# 입출력 데이터 통합하기
X = 
y =

"""### 문제 13. 학습데이터와 테스트데이터 분리하기

"""

from sklearn.model_selection import train_test_split

# train_test_split() 함수로 학습 데이터와 테스트 데이터 분리하기
X_train, X_test, y_train, y_test =

"""## Step 5. Regression 모델 학습하기

### 문제 14. XGBoost Regression 모델 학습하기
"""

from xgboost import XGBRegressor

# XGBRegressor 모델 생성/학습
model_reg =

"""### 문제 15. 모델 학습 결과 평가하기"""

from sklearn.metrics import mean_absolute_error, mean_squared_error
from math import sqrt

# Predict를 수행하고 mean_absolute_error, rmse 결과 출력하기
pred =

"""## Step 6. 모델 학습 결과 심화 분석하기

### 문제 16. 실제 값과 추측 값의 Scatter plot 시각화하기
"""

# y_test vs. pred Scatter 플랏으로 시각적으로 분석하기
# Hint) Scatter로 시각적 확인이 어려울 경우, histplot 등 활용

"""### 문제 17. 에러 값의 히스토그램 확인하기

"""

# err의 히스토그램으로 에러율 히스토그램 확인하기
err = (pred - y_test) / y_test