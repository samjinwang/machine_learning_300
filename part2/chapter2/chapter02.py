# -*- coding: utf-8 -*-
"""Chapter 2 - 뉴욕에서 방이 둘 딸린 집을 에어비엔비에 내놓으려 한다, 이 때 적당한 숙박료를 구하시오(문제).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Kp-1IjqvHkP45Vt0y8-f_XMdHMvudRfW

# 주제 : 뉴욕에서 방이 둘 딸린 집을 에어비엔비에 내놓으려 한다. 이 때 적당한 숙박료를 구하시오. (5점)
----------

## 실습 가이드
    1. 데이터를 다운로드하여 Colab에 불러옵니다.
    2. 필요한 라이브러리는 모두 코드로 작성되어 있습니다.
    3. 코드는 위에서부터 아래로 순서대로 실행합니다.
    
    
## 데이터 소개
    - 이번 주제는 New York City Airbnb Open Data를 사용합니다.
    
    - 다음 1개의 csv 파일을 사용합니다.
    AB_NYC_2019.csv
    
    - 각 파일의 컬럼은 아래와 같습니다.
    id: 항목의 ID
    name: 항목의 이름 (타이틀)
    host_id: 호스트 ID
    host_name: 호스트의 이름
    neighbourhood_group: 방이 있는 구역 그룹
    neighbourhood: 방이 있는 구역
    latitude: 방이 위치한 위도
    longitude: 방이 위치한 경도
    room_type: 방의 종류
    price: 가격 (미 달러)
    minimum_nights: 최소 숙박 일수
    number_of_reviews: 리뷰의 개수
    last_review: 마지막 리뷰 일자
    reviews_per_month: 월별 리뷰 개수
    calculated_host_listings_count: 호스트가 올린 방 개수
    availability_365: 365일 중 가능한 일수

    
- 데이터 출처: https://www.kaggle.com/dgomonov/new-york-city-airbnb-open-data

## 최종 목표
    - 스크래핑된 dirty 데이터 클리닝 방법 이해
    - 다양한 종류의 데이터 정규화 방법 습득
    - 데이터 시각화를 통한 인사이트 습득 방법의 이해
    - Scikit-learn 기반의 모델 학습 방법 습득
    - 학습된 모델로 부터의 인사이트 획득 방법 습득

- 출제자 : 신제용 강사
---

## Step 0. Regression에 대하여

### 선형 회귀에 대하여
Linear Regression: 하나의 값을 추정할때 
여러개 입력된 값 (M개의 feature vector)의 각각의 weight을 곱해 하나의 값을 얻어내려함

### 그 외의 회귀 방법
노트필기

## Step 1. 데이터셋 준비하기
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

"""### 문제 1. Colab Notebook에 Kaggle API 세팅하기

"""

import os

# os.environ을 이용하여 Kaggle API Username, Key 세팅하기
# os.environ을 이용하여 Kaggle API Username, Key 세팅하기
os.environ['KAGGLE_USERNAME'] = 'samjinwang'
os.environ['KAGGLE_KEY'] = 'e808743bea20e4a89b105256b9d5941b'

"""### 문제 2. 데이터 다운로드 및 압축 해제하기

"""

# Linux 명령어로 Kaggle API를 이용하여 데이터셋 다운로드하기 (!kaggle ~)
# Linux 명령어로 압축 해제하기
!rm *.*
!kaggle datasets download -d dgomonov/new-york-city-airbnb-open-data
!unzip '*.zip'

"""### 문제 3. Pandas 라이브러리로 csv파일 읽어들이기

"""

df = pd.read_csv('AB_NYC_2019.csv')

df.head()

"""## Step 2. EDA 및 데이터 기초 통계 분석

### 문제 4. 불필요한 데이터 데이터프레임에서 제거하기
"""

# DataFrame에서 제공하는 메소드를 이용하여 각 데이터프레임의 구조 분석하기 (head(), info(), describe())
# 데이터프레임에서 불필요한 컬럼 제거하기
df.head()
#name: 각 집마다 키워드을 잘 적어놓으려고 하고있다 -> 현재는 자연어 처리를 하지 않기 때문에 빼고간다
#host_id : 낮을수록 값이 집의 값이 커짐
#host_name: 크게 의미 없음
#neighbourhodd: 의밍ㅆ음
#latitude, longtitude: neighbourhood 값이 있기때문에 빼고 진행
#

df['room_type'].value_counts() #의미 있어 보임

df.info() #last review와 review per month의 숫자가 같다 
#calculated_host_listings_count 숫자 값이니 그냥 남겨둠

(df['reviews_per_month'].isna() & df['last_review'].isna()).sum() #두개다 True 여야 True

df['reviews_per_month'].isna().sum() #위에랑 결측값이 같은걸 보니 완전히 겹친다고 본다

df['availability_365'].hist()

(df['availability_365'] == 0).sum() #365일중 총 0일 숙박 가능한곳의 숫자 -> 17000개나됨 -> 결측값들임

df.isna().sum() #review가 있는 경우랑 없는경우로 나눠서 쓰기로 함

df.describe()
#host_id 값들의 차이가 많이 남
#price의 경우 min 이 0 max 10000 잘못 들어간 값으로 추정됨
#minimum_night : max가 1250인게 좀 이상함
#number of review : min이 0이다
#availability: max가 365인건 말이 되지만 min이 0인건 값이 입력 안됐다고 보여짐

(df['number_of_reviews']==0).sum() # 다른 review 데이터랑 겹치는듯

df.columns

df.drop(['id', 'name', 'host_name', 'latitude', 'longitude'], axis = 1, inplace = True)

df.head()

"""### 문제 5. 수치형 데이터와 Price의 Jointplot 분석하기

"""

df.columns

sns.jointplot(x='host_id', y = 'price',data =df, kind = 'hex') #상관성이 매우 적음! -> 수치형 데이터 클리닝후 다시 볼 필요가 있다

sns.jointplot(x='reviews_per_month', y = 'price',data =df, kind = 'hex') #이것도 아래에 몰려있음 -> price가 아웃라이어가 많기 때문일듯 -> 데이터 클리닝 해야할듯



"""### 문제 6. 수치형 데이터와 Price의 상관성 분석하기"""

sns.heatmap(df.corr(),annot = True, cmap = 'YlOrRd')
#price와의 상관성이 모든 컬럼에서 매우 낮게 나타남

#host_id와 review per month의 상관성이 높음 -> 숫자가 높은 호스트 (최근호스트)일 수록 월별평이 많다는것
#그에 비해 number of reviews는 상관관계가 낮음 -> 숫자가 높은 호스트가 전체 리뷰수는 적을수 밖에 없기 때문
#host_id와 calculated_host_listing_count -> 상관성이 있는편 -> 나중에 들어온 호스트가 집을 더 가진 확률이 높다

"""### 문제 7. 범주형 데이터와 Price의 Boxplot 계열 및 Histogram 분석하기"""

sns.boxplot(x = 'neighbourhood_group', y = 'price', data = df) #아웃라이어가 많아 보기 힘듬

sns.boxplot(x = 'room_type', y = 'price', data = df) #마찬가지

"""## Step 3. 데이터 클리닝 수행하기

### 문제 8. 미기입, 오기입 데이터 확인하기
"""

# 각 컬럼을 분석하여 미기입/오기입된 데이터 확인하기
# Hint) 수치형 데이터는 통계를 이용해서, 범주형 데이터는 unique(), value_counts()등으로 확인

"""### 문제 9. 아웃라이어를 제거하고 통계 재분석하기"""

# quantile(), drop() 등 메소드를 이용하여 outlier 제거하고 통계 재분석하기

"""### 문제 10. 미기입 데이터 처리하기"""

# fill(), dropna() 등으로 미기입된 데이터를 처리하기

"""## Step 4. 모델 학습을 위한 데이터 전처리

### 문제 11. get_dummies를 이용한 범주형 데이터 전처리
"""

X_cat =

"""### 문제 12. StandardScaler를 이용해 수치형 데이터 표준화하기

"""

from sklearn.preprocessing import StandardScaler

# StandardScaler를 이용해 수치형 데이터를 표준화하기
scaler = 
X_num = 

X = 
y =

"""### 문제 13. 학습데이터와 테스트데이터 분리하기

"""

from sklearn.model_selection import train_test_split

# train_test_split() 함수로 학습 데이터와 테스트 데이터 분리하기
X_train, X_test, y_train, y_test =

"""## Step 5. Regression 모델 학습하기

### 문제 14. XGBoost Regression 모델 학습하기
"""

from xgboost import XGBRegressor

# XGBRegressor 모델 생성/학습
model_reg =

"""### 문제 15. 모델 학습 결과 평가하기"""

from sklearn.metrics import mean_absolute_error, mean_squared_error

# Predict를 수행하고 mean_absolute_error, rmse 결과 출력하기
pred =

"""## Step 6. 모델 학습 결과 심화 분석하기

### 문제 16. 실제 값과 추측 값의 Scatter plot 시각화하기
"""

# y_test vs. pred Scatter 플랏으로 시각적으로 분석하기

"""### 문제 17. 에러 값의 히스토그램 확인하기

"""

# err의 히스토그램으로 에러율 히스토그램 확인하기
err = pred - y_test

